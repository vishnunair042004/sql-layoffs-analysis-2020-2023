
---

# ğŸ“Š **Global Layoffs Analysis (2020â€“2023) â€” SQL Project**

This project analyzes global layoff trends from 2020 to 2023 using SQL.
The workflow includes **data cleaning**, **standardization**, and **exploratory data analysis (EDA)** performed entirely in SQL.

The dataset is taken from Kaggle:
*â€œLayoffs Dataset (2022â€“2023)â€ by Swaptr.*
https://www.kaggle.com/datasets/swaptr/layoffs-2022

---

# ğŸ› ï¸ **Project Workflow**

This project consists of two main parts:

1. **Data Cleaning (SQL)**
2. **Exploratory Data Analysis (SQL)** *(will be added soon)*

Below is the full documentation for the **Data Cleaning** process.

---

# ğŸ§¹ **1. Data Cleaning**

The raw dataset contained inconsistencies, duplicates, missing values, and formatting issues.
A structured, step-by-step cleaning approach was used to create a clean and analysis-ready dataset.

---

## âœ… **Step 1 â€” Create a Staging Table**

A staging table (`layoffs_staging`) was created to ensure the **raw data remains untouched**:

* Cloned table schema
* Inserted raw data into the staging table
* All cleaning operations were done on the staging copy

This protects the original dataset and ensures reversible operations.

---

## âœ… **Step 2 â€” Identifying & Removing Duplicates**

Duplicate records were detected using `ROW_NUMBER()` with a `PARTITION BY` clause on:

* company
* location
* industry
* total_laid_off
* percentage_laid_off
* date
* stage
* country
* funds_raised_millions

Two approaches were explored:

### âœ”ï¸ Approach A: CTE-based duplicate removal

(Attempted but MySQL doesn't support deleting directly from CTE)

### âœ”ï¸ Approach B:

A more reliable method was implemented:

1. Created a new table `layoffs_staging2`
2. Added a `row_num` column using `ROW_NUMBER()`
3. Deleted all rows where `row_num >= 2`
4. Dropped the `row_num` column after cleanup

This fully removed all true duplicates while preserving the first valid record.

---

## âœ… **Step 3 â€” Standardizing Data**

Several inconsistencies were corrected to ensure uniformity across categories.

### ğŸ”¹ **3.1 Fixing Blank & NULL Industry Values**

* Empty strings were converted to `NULL`
* Missing industries were backfilled by matching company names
* If a company had at least one valid industry, the NULL rows were updated

This automated backfilling avoided manual corrections.

---

### ğŸ”¹ **3.2 Standardizing Industry Names**

Inconsistent crypto labels were standardized:

* "CryptoCurrency" â†’ "Crypto"
* "Crypto Currency" â†’ "Crypto"

---

### ğŸ”¹ **3.3 Cleaning Country Names**

Some rows contained `"United States."` (with trailing period).
Used:

```
TRIM(TRAILING '.' FROM country)
```

to standardize the country values.

---

### ğŸ”¹ **3.4 Converting Date Format to DATE Type**

The `date` field was stored as **text ("MM/DD/YYYY")**.

Steps:

1. Converted text â†’ date using `STR_TO_DATE()`
2. Updated column type to SQL `DATE`

This enables proper date-based analysis during EDA.

---

## âœ… **Step 4 â€” Handling NULL Values**

Columns such as:

* `total_laid_off`
* `percentage_laid_off`
* `funds_raised_millions`

had valid NULL values representing missing or undisclosed information.

These NULLs were kept intentionally because:

* They preserve original meaning
* They are useful in EDA (e.g., filtering rows with incomplete information)

---

## âœ… **Step 5 â€” Removing Useless Rows**

Rows where **both**:

* `total_laid_off IS NULL`
* `percentage_laid_off IS NULL`

were deleted because they provide no value for analysis.

---

## ğŸ“ **Final Cleaned Dataset**

After cleaning, `layoffs_staging2` contains:

* No duplicates
* Standardized industries and countries
* Proper DATE format
* Filled missing industry values
* Only meaningful rows retained

This dataset is now ready for the **Exploratory Data Analysis (EDA)** phase.

---

# ğŸ” **2. Exploratory Data Analysis (EDA)**

*(To be added once EDA queries are shared.)*

The EDA section will include:

* Layoffs by year
* Layoffs by country
* Layoffs by industry
* Layoffs by company
* Funding vs layoffs
* Stage-wise analysis
* Month-over-month trends

---

# ğŸ“¦ **Repository Structure (Recommended)**

```
ğŸ“ global-layoffs-sql-analysis
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ layoffs_raw.csv
â”‚   â””â”€â”€ layoffs_cleaned.csv
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 1_data_cleaning/
â”‚   â””â”€â”€ 2_eda/
â”‚
â””â”€â”€ screenshots/
```

---

If you want, I can now also create the:

âœ” **EDA README section**
âœ” **SQL file names & descriptions**
âœ” **Full repository README.md combining cleaning + EDA**

Just share your EDA SQL queries next.
